# üïµÔ∏è‚Äç‚ôÇÔ∏è Modelo de Detecci√≥n de Fraudes en Transacciones Bancarias

**Autores:**  
Gonz√°lez G. Jer√≥nimo  
V√©lez D. Daniel  
Villada C. Juan Jos√©  

**Semestre:** 2025-II
---

## üìò Descripci√≥n General

Este proyecto implementa y eval√∫a modelos supervisados de **Machine Learning** para la **detecci√≥n de fraude en transacciones financieras m√≥viles**, utilizando el dataset **PaySim**, un simulador basado en datos reales de una empresa africana (L√≥pez-Rojas et al., 2016).

El objetivo principal es analizar la eficacia de modelos como **XGBoost** y **Random Forest** frente al problema del **desbalance extremo de clases**, aplicando t√©cnicas de *resampling* y evaluando m√©tricas espec√≠ficas para este tipo de escenarios.

El trabajo forma parte de un estudio acad√©mico enfocado en **detecci√≥n de fraude explicable, reproducible y eficiente** dentro del dominio financiero.

---

## üß† Pregunta de Investigaci√≥n

> ¬øC√≥mo pueden los modelos de aprendizaje autom√°tico detectar eficazmente transacciones fraudulentas en dinero m√≥vil, considerando el fuerte desbalance de clases y la necesidad de interpretabilidad b√°sica?

---

## üéØ Objetivos SMART

- **Specific:** Entrenar y evaluar un modelo supervisado (XGBoost / Random Forest) sobre PaySim.  
- **Measurable:** Medir desempe√±o mediante **PR-AUC** y **F1-score**, antes y despu√©s del balanceo.  
- **Achievable:** Aplicar t√©cnicas de *resampling* (SMOTE) y analizar la importancia de variables.  
- **Relevant:** Evaluar qu√© factores explican mejor la predicci√≥n de fraude.  
- **Time-bound:** Desarrollar y documentar el proyecto durante el semestre acad√©mico **2025-II**.

---

## üìä Dataset: PaySim

- **Fuente:** Kaggle ‚Äî [PaySim Synthetic Financial Transactions](https://www.kaggle.com/datasets/ealaxi/paysim1)  
- **Tama√±o:** ~6.3 millones de registros  
- **Clases:**  
  - `isFraud = 1` ‚Üí transacciones fraudulentas (~0.1%)  
  - `isFraud = 0` ‚Üí transacciones leg√≠timas  
- **Variables principales:**
  - `step`, `type`, `amount`, `oldbalanceOrg`, `newbalanceOrig`, `oldbalanceDest`, `newbalanceDest`
- **Features derivadas:**  
  - `diffOrg = oldbalanceOrg - newbalanceOrig`  
  - `diffDest = newbalanceDest - oldbalanceDest`  
  - `ratio = amount / (oldbalanceOrg + 1)`

---

## ‚öôÔ∏è Metodolog√≠a

### 1. Preprocesamiento
- Eliminaci√≥n de variables con fuga de informaci√≥n (`isFlaggedFraud`).  
- Codificaci√≥n categ√≥rica de `type` mediante *one-hot encoding*.  
- Creaci√≥n de variables derivadas (`diffOrg`, `diffDest`, `ratio`).  
- Escalado con **MinMaxScaler**.  

### 2. Balanceo de Clases
- Aplicaci√≥n de **SMOTE (Synthetic Minority Oversampling Technique)** con ratio 1:2 (fraude:no fraude).  
- Divisi√≥n del dataset en entrenamiento (85%) y prueba (15%) estratificados.

### 3. Modelado
- **Modelo principal:** XGBoost  
- **Baseline:** Random Forest (15% del dataset balanceado)  
- **Validaci√≥n cruzada:** 5-fold estratificada  
- **Semilla:** 42 (para reproducibilidad)

### 4. M√©tricas de Evaluaci√≥n
- **F1-score**
- **Precision**
- **Recall**
- **PR-AUC (Precision-Recall Area Under Curve)** ‚Äî m√©trica principal

---

## üßæ Resultados Principales

| Modelo | F1-score | Precision | Recall | PR-AUC |
|--------|-----------|-----------|--------|--------|
| **XGBoost** | 0.941 | 0.8911 | 0.9968 | 0.9978 |
| **Random Forest** | 0.9812 | 0.9654 | 0.9976 | ‚Äî |

üìå El modelo XGBoost detect√≥ pr√°cticamente todos los fraudes, con un F1-score de 0.94 y un PR-AUC de 0.9978.  
Las variables m√°s influyentes fueron `diffOrg`, `newbalanceOrig` y `ratio`.

---

## üí¨ Discusi√≥n

- **Rendimiento:** el modelo logra alta sensibilidad (recall ‚âà 0.99) y buena precisi√≥n (~0.89), equilibrando detecci√≥n y control de falsos positivos.  
- **Interpretabilidad:** las variables derivadas basadas en balances (`diffOrg`) resultaron cr√≠ticas.  
- **Limitaciones:** uso de datos sint√©ticos, falta de validaci√≥n temporal y posibles efectos del oversampling artificial.  
- **Aplicabilidad:** el modelo es viable para sistemas antifraude en tiempo real con monitoreo peri√≥dico y revisi√≥n manual en casos de incertidumbre.

---

## üöÄ Reproducci√≥n del Experimento

### Ejecuci√≥n en Google Colab
1. Clonar este repositorio o subir los archivos `.ipynb` y `paysim.csv`.  
2. Subir el dataset a la sesi√≥n de Colab (`Archivos ‚Üí Subir`).  
3. Instalar dependencias necesarias:
   ```bash
   !pip install xgboost imbalanced-learn scikit-learn shap
